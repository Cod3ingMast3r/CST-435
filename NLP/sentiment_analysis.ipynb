{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c0682a5d563a17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### load all the libraries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4576e89f73c4dfe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T19:56:32.316060Z",
     "start_time": "2023-10-11T19:56:32.299664Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "# Variables to set the number of epochs and samples\n",
    "num_epochs = 10\n",
    "num_samples = 100  # set this to -1 to use all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad29677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.version.cuda)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd761ce092191106",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### load the dataset and the model tokenizer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6071385fed8e1189",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/matth/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 136.35it/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 6.70MB/s]\n",
      "d:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\matth\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load dataset and model tokenizer\n",
    "dataset = load_dataset('imdb')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58047696700adf4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### create a plot to see the distribution of the positive and negative classes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1353a8e1e70ff11e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Exploration\n",
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "sns.countplot(x='label', data=train_df)\n",
    "plt.title('Class distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea3f9621a6b692",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### preprocess our dataset by tokenizing the texts. We use BERT’s tokenizer, which will convert the text into tokens that correspond to BERT’s vocabulary ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcbad849c5a40bdf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "# Step 2: Preprocess the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ca7c67c692a669",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# prepare our training and evaluation datasets. Remember, if you want to use all the data, you can set the num_samples variable to -1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997d7bb5c9da3ee5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if num_samples == -1:\n",
    "    small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "    small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)\n",
    "else:\n",
    "    small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(num_samples)) \n",
    "    small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(num_samples)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d35802407bcd6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### load the pre-trained BERT model. We’ll use the AutoModelForSequenceClassification class, a BERT model designed for classification tasks ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ccca7f9fb18dd9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### *use the ‘bert-base-uncased’ version of BERT, which is trained on lower-case English text* ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57df9797fbd20332",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [00:34<00:00, 12.8MB/s] \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7125357a05d4815",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### define our training arguments and create a Trainer instance to train our model. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08de11d96a5b743",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  1%|          | 1/130 [00:16<36:11, 16.83s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Classes\\CST-435\\NLP\\sentiment_analysis.ipynb Cell 15\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Classes/CST-435/NLP/sentiment_analysis.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Step 5: Create Trainer instance and train\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Classes/CST-435/NLP/sentiment_analysis.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Classes/CST-435/NLP/sentiment_analysis.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel, args\u001b[39m=\u001b[39mtraining_args, train_dataset\u001b[39m=\u001b[39msmall_train_dataset, eval_dataset\u001b[39m=\u001b[39msmall_eval_dataset\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Classes/CST-435/NLP/sentiment_analysis.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Classes/CST-435/NLP/sentiment_analysis.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1632\u001b[0m )\n\u001b[1;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1638\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1900\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1902\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1905\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1906\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1907\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1908\u001b[0m ):\n\u001b[0;32m   1909\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:2663\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2661\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed\u001b[39m.\u001b[39mbackward(loss)\n\u001b[0;32m   2662\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2663\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m   2665\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[1;32md:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\matth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 4: Define training arguments\n",
    "training_args = TrainingArguments(\"test_trainer\", evaluation_strategy=\"epoch\", no_cuda=True, num_train_epochs=num_epochs)\n",
    "\n",
    "# Step 5: Create Trainer instance and train\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9dded99d5064c1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Interpreting Results ###\n",
    "Having trained our model, let’s evaluate it. We’ll calculate the confusion matrix and the ROC curve to understand how well our model performs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55734817556fa9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 6: Evaluation\n",
    "predictions = trainer.predict(small_eval_dataset)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(small_eval_dataset['label'], predictions.predictions.argmax(-1))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(small_eval_dataset['label'], predictions.predictions[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(1.618 * 5, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d271f621f7f6dfe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### The confusion matrix gives a detailed breakdown of how our predictions measure up to the actual labels, while the ROC curve shows us the trade-off between the true positive rate (sensitivity) and the false positive rate (1 — specificity) at various threshold settings ###\n",
    "\n",
    "### see our model in action, use it to infer the sentiment of a sample text ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee8298a763e2098",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 7: Inference on a new sample\n",
    "sample_text = \"This is a fantastic movie. I really enjoyed it.\"\n",
    "sample_inputs = tokenizer(sample_text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Move inputs to device (if GPU available)\n",
    "sample_inputs.to(training_args.device)\n",
    "\n",
    "# Make prediction\n",
    "predictions = model(**sample_inputs)\n",
    "predicted_class = predictions.logits.argmax(-1).item()\n",
    "\n",
    "if predicted_class == 1:\n",
    "    print(\"Positive sentiment\")\n",
    "else:\n",
    "    print(\"Negative sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
